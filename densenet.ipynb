{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14774,"databundleVersionId":875431,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:45:32.954365Z","iopub.execute_input":"2025-05-21T14:45:32.954578Z","iopub.status.idle":"2025-05-21T14:45:42.252395Z","shell.execute_reply.started":"2025-05-21T14:45:32.954560Z","shell.execute_reply":"2025-05-21T14:45:42.251732Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:45:42.253848Z","iopub.execute_input":"2025-05-21T14:45:42.254270Z","iopub.status.idle":"2025-05-21T14:45:49.733192Z","shell.execute_reply.started":"2025-05-21T14:45:42.254244Z","shell.execute_reply":"2025-05-21T14:45:49.732485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nimage_dir = \"/kaggle/input/aptos2019-blindness-detection/train_images\"\ntrain_csv_path = \"/kaggle/input/aptos2019-blindness-detection/train.csv\"\n\ndf = pd.read_csv(train_csv_path)\ndf['diagnosis'] = df['diagnosis'].astype(int)\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(df, stratify=df['diagnosis'], test_size=0.2, random_state=42)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:45:49.733815Z","iopub.execute_input":"2025-05-21T14:45:49.734128Z","iopub.status.idle":"2025-05-21T14:45:50.360889Z","shell.execute_reply.started":"2025-05-21T14:45:49.734110Z","shell.execute_reply":"2025-05-21T14:45:50.360118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RetinaDataset(Dataset):\n    def __init__(self, df, image_dir, transform=None):\n        self.df = df\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = f\"{self.image_dir}/{row['id_code']}.png\"\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        label = int(row['diagnosis'])\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:46:00.099483Z","iopub.execute_input":"2025-05-21T14:46:00.099754Z","iopub.status.idle":"2025-05-21T14:46:00.104909Z","shell.execute_reply.started":"2025-05-21T14:46:00.099733Z","shell.execute_reply":"2025-05-21T14:46:00.104105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = RetinaDataset(train_df, image_dir, transform=train_transform)\nval_dataset = RetinaDataset(val_df, image_dir, transform=val_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\nclass_counts = train_df['diagnosis'].value_counts().sort_index().values\nclass_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\nclass_weights = class_weights / class_weights.sum()\nclass_weights = class_weights.to(device)\n\nmodel = models.densenet121(pretrained=True)\nmodel.classifier = nn.Linear(model.classifier.in_features, 5)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\nscheduler = ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5, verbose=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:46:11.910171Z","iopub.execute_input":"2025-05-21T14:46:11.910684Z","iopub.status.idle":"2025-05-21T14:46:13.104884Z","shell.execute_reply.started":"2025-05-21T14:46:11.910662Z","shell.execute_reply":"2025-05-21T14:46:13.104133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 10\nbest_acc = 0.0\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    print(f\"\\n Epoch {epoch+1}/{num_epochs} started\")\n\n    for batch_idx, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        if batch_idx % 30 == 0:\n            print(f\"  Batch {batch_idx} — Loss: {loss.item():.4f}\")\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100. * correct / total\n\n    print(f\" Epoch [{epoch+1}/{num_epochs}] — Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n    scheduler.step(epoch_acc)\n\n    if epoch_acc > best_acc:\n        best_acc = epoch_acc\n        torch.save(model.state_dict(), \"/kaggle/working/densenet121_best.pth\")\n        print(\" Best DenseNet model saved\")\n\nprint(f\"\\n Finished. Best Accuracy: {best_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:46:42.439721Z","iopub.execute_input":"2025-05-21T14:46:42.440412Z","iopub.status.idle":"2025-05-21T15:53:00.753680Z","shell.execute_reply.started":"2025-05-21T14:46:42.440389Z","shell.execute_reply":"2025-05-21T15:53:00.753005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nmodel.load_state_dict(torch.load(\"/kaggle/working/densenet121_best.pth\"))\nmodel.to(device)\nmodel.eval()\n\nval_loss = 0.0\ncorrect = 0\ntotal = 0\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        val_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        all_preds.extend(predicted.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nval_loss /= len(val_loader)\nval_acc = 100. * correct / total\n\nprint(f\"\\n Validation Loss: {val_loss:.4f}\")\nprint(f\" Validation Accuracy: {val_acc:.2f}%\")\n\ncm = confusion_matrix(all_labels, all_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2, 3, 4])\n\nplt.figure(figsize=(6, 6))\ndisp.plot(cmap='Blues', values_format='d')\nplt.title(\"Confusion Matrix — DenseNet121\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:07:10.436922Z","iopub.execute_input":"2025-05-21T16:07:10.437570Z","iopub.status.idle":"2025-05-21T16:08:56.171724Z","shell.execute_reply.started":"2025-05-21T16:07:10.437547Z","shell.execute_reply":"2025-05-21T16:08:56.171139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision.models import densenet121\n\nstrong_aug = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n    transforms.RandomAffine(degrees=20, shear=15),\n    transforms.ToTensor(),  # <- преобразуем в Tensor перед RandomErasing\n    transforms.RandomErasing(p=0.25, scale=(0.02, 0.15)),\n    transforms.Normalize([0.5], [0.5])\n])\n\ntrain_dataset = RetinaDataset(train_df, image_dir, transform=strong_aug)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nmodel.load_state_dict(torch.load(\"/kaggle/working/densenet121_best.pth\"))\nmodel.to(device)\nfor param in model.parameters():\n    param.requires_grad = True\n\nclass_counts = train_df['diagnosis'].value_counts().sort_index().values\nclass_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\nclass_weights = class_weights / class_weights.sum()\nclass_weights = class_weights.to(device)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.parameters(), lr=0.0002)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\nnum_epochs = 10\nbest_acc = 0.0\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    print(f\"\\n Epoch {epoch + 1}/{num_epochs} started\")\n\n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (preds == labels).sum().item()\n\n        if i % 30 == 0:\n            print(f\"  Batch {i} — Loss: {loss.item():.4f}\")\n\n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100. * correct / total\n\n    print(f\" Epoch [{epoch+1}/{num_epochs}] — Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n\n    scheduler.step(epoch_loss)\n\n    if epoch_acc > best_acc:\n        best_acc = epoch_acc\n        torch.save(model.state_dict(), \"/kaggle/working/densenet121_boosted_v2.pth\")\n        print(\" New boosted model saved\")\n\nprint(f\"\\n Done! Final best accuracy: {best_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:24:58.751462Z","iopub.execute_input":"2025-05-21T16:24:58.751963Z","iopub.status.idle":"2025-05-21T17:29:44.843544Z","shell.execute_reply.started":"2025-05-21T16:24:58.751939Z","shell.execute_reply":"2025-05-21T17:29:44.842629Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:49:07.729298Z","iopub.execute_input":"2025-05-21T17:49:07.729606Z","iopub.status.idle":"2025-05-21T17:49:08.082896Z","shell.execute_reply.started":"2025-05-21T17:49:07.729585Z","shell.execute_reply":"2025-05-21T17:49:08.082395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"densenet121_boosted_v2.pth\"))\nmodel.eval()\n\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\nprint(classification_report(y_true, y_pred, digits=4))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\nplt.title(\"Confusion Matrix — DenseNet121\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.savefig(\"densenet121_confusion.png\")  \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:49:12.790704Z","iopub.execute_input":"2025-05-21T17:49:12.791140Z","iopub.status.idle":"2025-05-21T17:50:44.206982Z","shell.execute_reply.started":"2025-05-21T17:49:12.791117Z","shell.execute_reply":"2025-05-21T17:50:44.206326Z"}},"outputs":[],"execution_count":null}]}